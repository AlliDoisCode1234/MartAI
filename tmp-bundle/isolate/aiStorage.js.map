{
  "version": 3,
  "sources": ["../convex/aiStorage.ts"],
  "sourcesContent": ["import { v } from 'convex/values';\r\nimport { internalMutation, internalQuery } from './_generated/server';\r\nimport { totalGenerations, costPerProject } from './analytics/aggregations';\r\n\r\nexport const getStored = internalQuery({\r\n  args: {\r\n    inputHash: v.string(),\r\n  },\r\n  handler: async (ctx, args) => {\r\n    return await ctx.db\r\n      .query('aiGenerations')\r\n      .withIndex('by_hash', (q) => q.eq('inputHash', args.inputHash))\r\n      .first();\r\n  },\r\n});\r\n\r\nexport const store = internalMutation({\r\n  args: {\r\n    inputHash: v.string(),\r\n    operation: v.string(),\r\n    provider: v.optional(v.string()),\r\n    model: v.optional(v.string()),\r\n    inputArgs: v.any(),\r\n    output: v.any(),\r\n    tokensIn: v.optional(v.number()),\r\n    tokensOut: v.optional(v.number()),\r\n    cost: v.optional(v.number()),\r\n    metadata: v.optional(v.any()),\r\n  },\r\n  handler: async (ctx, args) => {\r\n    // Check for collision/duplicate just in case, though hash should be unique enough for our purpose\r\n    // If it exists, we could update it or just ignore. Ideally, we just create a new entry if we want an audit log of *attempts*,\r\n    // but the user want storage for *retrieval*.\r\n    // If we want it to be a cache, we should just return if it exists?\r\n    // But hashing might have collisions (unlikely with SHA256 of full inputs).\r\n    // Let's just blindly insert for now as an audit log. The 'getStored' will pick the first one.\r\n\r\n    // Actually, if we want an audit log, we insert every time.\r\n    // If we simply want a cache, we could check existence.\r\n    // Given the requirement \"store all data we get... and see if we have data before we use\",\r\n    // we should treat it as a cache.\r\n    // However, if we re-run an action despite cache (e.g. forced), we might want to log it.\r\n    // Let's insert. The usage pattern will be: check -> if miss -> fetch -> store.\r\n\r\n    await ctx.db.insert('aiGenerations', {\r\n      ...args,\r\n      createdAt: Date.now(),\r\n    });\r\n\r\n    try {\r\n      /*\r\n      await (totalGenerations as any).insert(ctx, {\r\n        value: 1, // Count 1 generation\r\n      });\r\n\r\n      if (args.metadata && args.metadata.projectId && args.cost) {\r\n        await (costPerProject as any).insert(ctx, {\r\n          value: args.cost,\r\n          key: args.metadata.projectId,\r\n        });\r\n      }\r\n      */\r\n    } catch (e) {\r\n      console.error('Failed to update aggregations', e);\r\n    }\r\n  },\r\n});\r\n"],
  "mappings": ";;;;;;;;;;;;;AAAAA;AAIO,IAAMC,IAAYC,EAAc;AAAA,EACrC,MAAM;AAAA,IACJ,WAAWC,EAAE,OAAO;AAAA,EACtB;AAAA,EACA,SAAS,gBAAAC,EAAA,OAAOC,GAAKC,MACZ,MAAMD,EAAI,GACd,MAAM,eAAe,EACrB,UAAU,WAAW,CAACE,MAAMA,EAAE,GAAG,aAAaD,EAAK,SAAS,CAAC,EAC7D,MAAM,GAJF;AAMX,CAAC,GAEYE,IAAQC,EAAiB;AAAA,EACpC,MAAM;AAAA,IACJ,WAAWN,EAAE,OAAO;AAAA,IACpB,WAAWA,EAAE,OAAO;AAAA,IACpB,UAAUA,EAAE,SAASA,EAAE,OAAO,CAAC;AAAA,IAC/B,OAAOA,EAAE,SAASA,EAAE,OAAO,CAAC;AAAA,IAC5B,WAAWA,EAAE,IAAI;AAAA,IACjB,QAAQA,EAAE,IAAI;AAAA,IACd,UAAUA,EAAE,SAASA,EAAE,OAAO,CAAC;AAAA,IAC/B,WAAWA,EAAE,SAASA,EAAE,OAAO,CAAC;AAAA,IAChC,MAAMA,EAAE,SAASA,EAAE,OAAO,CAAC;AAAA,IAC3B,UAAUA,EAAE,SAASA,EAAE,IAAI,CAAC;AAAA,EAC9B;AAAA,EACA,SAAS,gBAAAC,EAAA,OAAOC,GAAKC,MAAS;AAe5B,UAAMD,EAAI,GAAG,OAAO,iBAAiB;AAAA,MACnC,GAAGC;AAAA,MACH,WAAW,KAAK,IAAI;AAAA,IACtB,CAAC;AAAA,EAkBH,GApCS;AAqCX,CAAC;",
  "names": ["init_values", "getStored", "internalQuery", "v", "__name", "ctx", "args", "q", "store", "internalMutation"]
}
